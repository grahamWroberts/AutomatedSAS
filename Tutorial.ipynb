{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e921a03d-e0a7-4cf0-a2dd-5a142053b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"./src\")\n",
    "import run_model\n",
    "import types\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e34a409-635b-4828-9e9f-75cb366842a4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Default arguments\n",
    "Below are all of teh arguments and their default values \n",
    "\n",
    "- targets: the list of space separated target morphologies, \n",
    ">--targets cylinder disk sphere cs_cylinder cs_disk cs_sphere\n",
    "\n",
    "- datadir: A directory containing all the data. There should be a file called \"TRAIN_[target].csv\" and \"TEST_[target].csv\" for each target,\n",
    ">--datadir data\n",
    "- configdir: The directory containing the configuration files,\n",
    "- resultsdir: A directory to save results to.\n",
    ">--resultsdir results\n",
    "- hierarchy_file: A file contaiing the structure of the hierarchical model, should be in the configdir directory.\n",
    ">--hierarchy_file hierarchical_structure.txt\n",
    "- reg_file: A file containing the hyperparameters and targets for the regression models, should be in the configdir directory. must contain one set of hyperparmeters for each desired target for each morphology.\n",
    ">--reg_file krr_hyperparameters.txt\n",
    "- extrapolation: A flag for whether to limit the test data to aspect ratios and shell ratios outside the range of the training data.\n",
    ">--extrapolation False\n",
    "- evaluate_file: An optional path to a file containing curves to evaluate, this is where to point to new data of interest. Curves must have the same q values.\n",
    ">--evaluate_file None\n",
    "- quotient: A flag, if true pre-process with the a quotient transform as defined in B. Yildirim, J. Doutch and J. M. Cole, Digital Discovery, 2024,3, 694â€“704.\n",
    ">--quotient False\n",
    "- uncertainty: A flag, if true report uncertainty bounds on the curves in evaluate file, using conformal prediction\n",
    ">--uncertainty: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60bdd281-ba3b-4c80-82f4-03bb8c4be4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {\"targets\":['cylinder', 'disk', 'sphere', 'cs_cylinder', 'cs_disk', 'cs_sphere'],\n",
    "             \"datadir\": 'data',\n",
    "             \"configdir\": 'configs',\n",
    "             \"resultsdir\": 'results',\n",
    "             \"hierarchy_file\": 'hierarchical_structure.txt',\n",
    "             \"reg_file\": 'krr_hyperparameters.txt',\n",
    "             \"extrapolation\": False,\n",
    "             \"evaluate_file\": None,\n",
    "             \"quotient\": False}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a4e754-bcaa-4d32-a5f1-aa13cdb1df78",
   "metadata": {},
   "source": [
    "# Running the model\n",
    "\n",
    "This document help explain first how to run the model, and then dives a little deeper into how the model works.\n",
    "First we can run the model. \n",
    "there is a script to do this, called \"example_run.sh\" which sets a few arguments and runs the model.\n",
    "\n",
    "```python3 src/run_model.py  --datadir data --configdir configs --resultsdir results --evaluate_file ./data/experimental_curves.csv --extrapolation True```\n",
    "\n",
    "This configures a few key arguments and runs the full mmodel. \n",
    "The arguments it configures is \n",
    "\n",
    "1. datadir: the directory containing all the data. inthis case the directory called \"data.\"\n",
    "2. configdir: the directory containing the configuration files for the hierarchical model and each of the component classifiers, as well as a separate file for teh hyperparameters defining each of the regression models.\n",
    "3. evaluate_file: this is a separate file contains the experimental curves shown in the paper. These are curves that the model is not trained on. If you want to test the model on other data. point this argument there.\n",
    "4. extrapolation: This is a boolean flag specific to this application. In the accompanying peper we display results in which we only train on a subsampled training set containing only points with a small aspect ratio or shell-to-total ratio. If this flag is set to true, that is what is used. The performance will not be quite as strong as when all the data are used, so if trying to implement in practice set this to false.\n",
    "\n",
    "The other argumentas and to fully customize running the model are shown below. For now let's look at these results. We can also invoke the model from within this notebook. instead of the command line arguments a dictionary of arguments can be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c1b7c34-0fb5-47d8-a206-8eb51863329d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'arguments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43marguments\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluate_file\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/experimental_curves.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m arguments[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextrapolate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      3\u001b[0m arguments[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquotient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'arguments' is not defined"
     ]
    }
   ],
   "source": [
    "arguments[\"evaluate_file\"] =  './data/experimental_curves.csv'\n",
    "arguments[\"extrapolate\"] = True\n",
    "arguments[\"quotient\"] = True\n",
    "run_model.main(types.SimpleNamespace(**arguments))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f715171-6a0f-4c9d-bff2-68c369956ecd",
   "metadata": {},
   "source": [
    "## results\n",
    "The results are saved to the results directory\n",
    "\n",
    "1. *classification report* contains the same classification report printed when the model is run. This shows the breakdown of precision, recall, and f1-score of each class as well as the overall accuracy.\n",
    "2. *correct_<TARGET>.csv* contains the details of each correct curve, for each respective class. These contain both the structural parameters used to generate the data as well as the structural parameteres used for generating the curves, as well as the results of the regressions.\n",
    "each line starts with thhe index of that curve in its respective dataset, then the true structural parameters indicated by the all caps \"TRUE\".\n",
    "Following these are the structural parameters as suggested by the regression models, labeled with a capital \"REGRESSED\".\n",
    "3. *incorrect_<TARGET>.txt* are similar to their correct counterparts, but contain the respective incorrect curves, as well as the morphology those curves were classified as and the results of regression using those incorrect classes. In many cases these incorrect classes and structural parameters can in fact fit the curves quite well.\n",
    "These also start with the index and the true structual parameters, but the first entry in the \"REGRESSED\" section is the predicted morphology.\n",
    "\n",
    "These give detailed information both on the classification breakdown and on each individual regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34abda8a-9091-4df7-920d-ce7d4a2ec61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['classification_results.txt', 'correct_sphere.csv', 'incorrect_cs_disk', 'incorrect_cs_disk.txt', 'incorrect_cylinder', 'correct_cs_disk.csv', 'incorrect_disk.txt', 'incorrect_cs_cylinder.txt', 'incorrect_disk', 'incorrect_cylinder.txt', 'incorrect_sphere.txt', 'correct_cylinder.csv', 'incorrect_cs_cylinder', 'predictions.txt', 'correct_cs_sphere.csv', 'correct_disk.csv', 'correct_cs_cylinder.csv', 'incorrect_cs_sphere', 'incorrect_cs_sphere.txt', 'incorrect_sphere']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.94      0.94      1000\n",
      "         1.0       0.92      0.88      0.90      1000\n",
      "         2.0       0.91      0.98      0.95      1000\n",
      "         3.0       0.83      0.90      0.86      1000\n",
      "         4.0       0.84      0.80      0.82      1000\n",
      "         5.0       0.85      0.78      0.82      1000\n",
      "\n",
      "    accuracy                           0.88      6000\n",
      "   macro avg       0.88      0.88      0.88      6000\n",
      "weighted avg       0.88      0.88      0.88      6000\n",
      "\n",
      "0 TRUE radius:150.300549 length:624.930906 shell:27.395496 aspect_ratio:2.078938 shell_ratio:0.182271 REGRESSED radius:149.606275 length:589.163826 shell:30.683770\n",
      "\n",
      "1 TRUE radius:127.841556 length:560.261709 shell:25.303962 aspect_ratio:2.191235 shell_ratio:0.197932 REGRESSED radius:121.290837 length:856.074391 shell:25.557948\n",
      "\n",
      "2 TRUE radius:140.629504 length:596.476367 shell:27.996912 aspect_ratio:2.120737 shell_ratio:0.199083 REGRESSED radius:111.055565 length:638.705233 shell:33.482204\n",
      "\n",
      "3 TRUE radius:198.729928 length:805.136186 shell:49.000564 aspect_ratio:2.025704 shell_ratio:0.246569 REGRESSED radius:132.095230 length:2113.499494 shell:42.136357\n",
      "\n",
      "4 TRUE radius:150.616194 length:605.090845 shell:35.386016 aspect_ratio:2.008718 shell_ratio:0.234942 REGRESSED radius:126.566667 length:559.549500 shell:27.390840\n",
      "\n",
      "9 TRUE radius:89.938530 length:393.384474 shell:30.401053 aspect_ratio:2.186963 shell_ratio:0.338020 REGRESSED cs_sphere radius:105.655688 shell:34.351879 TeCsC0009 1.4418 0.4917\n",
      "\n",
      "73 TRUE radius:223.724290 length:1007.444186 shell:138.366353 aspect_ratio:2.251531 shell_ratio:0.618468 REGRESSED cs_sphere radius:322.884355 shell:131.636242 TeCsC0073 0.2647 0.5835\n",
      "\n",
      "109 TRUE radius:120.061911 length:638.276452 shell:55.611098 aspect_ratio:2.658114 shell_ratio:0.463187 REGRESSED cs_sphere radius:215.893860 shell:60.186100 TeCsC0109 0.5251 0.7247\n",
      "\n",
      "185 TRUE radius:178.644063 length:1128.865908 shell:38.779895 aspect_ratio:3.159539 shell_ratio:0.217079 REGRESSED cs_sphere radius:80.337488 shell:32.896454 TeCsC0185 1.1336 0.7221\n",
      "\n",
      "190 TRUE radius:81.542171 length:510.699298 shell:24.493859 aspect_ratio:3.131504 shell_ratio:0.300383 REGRESSED cs_sphere radius:44.374620 shell:28.615520 TeCsC0190 0.8828 0.9829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"results\"))\n",
    "classification_summary = open('results/classification_results.txt', 'r').readlines()\n",
    "classification_report = ''.join(classification_summary)\n",
    "print(classification_report)\n",
    "correct = open(\"results/correct_cs_cylinder.csv\", 'r').readlines()\n",
    "print(\"\\n\".join(correct[:5]))\n",
    "incorrect = open(\"results/incorrect_cs_cylinder.txt\", 'r').readlines()\n",
    "print(\"\\n\".join(incorrect[:5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52954714-2538-4159-a323-b5750bddaf79",
   "metadata": {},
   "source": [
    "## Quotient transform\n",
    "one of the arguments available is the quotient transform defined in [yldirim, Doutch, and Cole, 2024](https://pubs.rsc.org/en/content/articlelanding/2024/dd/d3dd00225j)\n",
    "in order to use the quotient transform use the argument \"--quotient True\" Below are the effects on our data\n",
    "|preprocessing|dataset|accuracy|f1-score|\n",
    "|:--|:--|:--|:--|\n",
    "Background subtraction & high-q shift|constant scale|0.88|0.88|\n",
    "||extrapolated scale|0.86|0.86|\n",
    "quotient transform|constant scale|0.84|0.84|\n",
    "||extrapolated scale|0.81|0.80\n",
    "\n",
    "background subtraction and high-q shift are the method preferred in our work. This involves subtracting out the background intensity of the curves, then vertically shifting all curves to have the same value in the high-q at incoherrence.\n",
    "\n",
    "quotient transform is a method in which the value of a point and index i is divided by the value at point i+1 prior to taking the log.\n",
    "\n",
    "In our study we maintained the value of the scale parameter at 1, in the scale extrapolated set we varied that parameter from 0.5 to 1.5 to evaluate fow variances in that parameter affected the reliability of our model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
